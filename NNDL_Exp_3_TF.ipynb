{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0I3Y/74MAzFqTmQO5vegN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishavRajSharma/NNDL-Lab/blob/main/NNDL_Exp_3_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "itolwuUWZWKf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Sample data\n",
        "X = np.random.rand(1000, 5)   # 5 transaction features\n",
        "y = (np.sum(X, axis=1) > 2.5).astype(int)  # simple fraud rule\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test = X[:800], X[800:]\n",
        "y_train, y_test = y[:800], y[800:]\n"
      ],
      "metadata": {
        "id": "FIGImTcaGZfa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(5,)),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16bRi_78G4EX",
        "outputId": "ae1dee8a-226c-46a2-95ec-b979e0e8e7de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "Nc59lx6WG9Vs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D04xPbbRHCLm",
        "outputId": "679299d8-25e7-4726-8d8e-401bba049b09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5069 - loss: 0.6971 - val_accuracy: 0.5562 - val_loss: 0.6804\n",
            "Epoch 2/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5544 - loss: 0.6834 - val_accuracy: 0.5750 - val_loss: 0.6716\n",
            "Epoch 3/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5538 - loss: 0.6828 - val_accuracy: 0.5813 - val_loss: 0.6624\n",
            "Epoch 4/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5948 - loss: 0.6647 - val_accuracy: 0.5875 - val_loss: 0.6535\n",
            "Epoch 5/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5698 - loss: 0.6644 - val_accuracy: 0.6313 - val_loss: 0.6442\n",
            "Epoch 6/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6317 - loss: 0.6433 - val_accuracy: 0.6438 - val_loss: 0.6351\n",
            "Epoch 7/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6541 - loss: 0.6374 - val_accuracy: 0.6500 - val_loss: 0.6258\n",
            "Epoch 8/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6507 - loss: 0.6302 - val_accuracy: 0.6812 - val_loss: 0.6152\n",
            "Epoch 9/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7179 - loss: 0.6116 - val_accuracy: 0.6938 - val_loss: 0.6035\n",
            "Epoch 10/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7117 - loss: 0.6083 - val_accuracy: 0.7437 - val_loss: 0.5899\n",
            "Epoch 11/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7363 - loss: 0.5925 - val_accuracy: 0.7500 - val_loss: 0.5752\n",
            "Epoch 12/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7463 - loss: 0.5702 - val_accuracy: 0.7688 - val_loss: 0.5583\n",
            "Epoch 13/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7852 - loss: 0.5638 - val_accuracy: 0.7937 - val_loss: 0.5414\n",
            "Epoch 14/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8227 - loss: 0.5330 - val_accuracy: 0.7937 - val_loss: 0.5242\n",
            "Epoch 15/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8258 - loss: 0.5291 - val_accuracy: 0.8125 - val_loss: 0.5060\n",
            "Epoch 16/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8158 - loss: 0.5004 - val_accuracy: 0.8250 - val_loss: 0.4871\n",
            "Epoch 17/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.4983 - val_accuracy: 0.8375 - val_loss: 0.4680\n",
            "Epoch 18/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 0.4645 - val_accuracy: 0.8687 - val_loss: 0.4477\n",
            "Epoch 19/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8772 - loss: 0.4394 - val_accuracy: 0.8750 - val_loss: 0.4272\n",
            "Epoch 20/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8975 - loss: 0.4177 - val_accuracy: 0.8813 - val_loss: 0.4067\n",
            "Epoch 21/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.3904 - val_accuracy: 0.9125 - val_loss: 0.3859\n",
            "Epoch 22/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.3789 - val_accuracy: 0.9250 - val_loss: 0.3654\n",
            "Epoch 23/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9337 - loss: 0.3557 - val_accuracy: 0.9625 - val_loss: 0.3464\n",
            "Epoch 24/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9305 - loss: 0.3400 - val_accuracy: 0.9625 - val_loss: 0.3268\n",
            "Epoch 25/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.3160 - val_accuracy: 0.9625 - val_loss: 0.3098\n",
            "Epoch 26/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.3101 - val_accuracy: 0.9625 - val_loss: 0.2921\n",
            "Epoch 27/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.2910 - val_accuracy: 0.9688 - val_loss: 0.2768\n",
            "Epoch 28/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9423 - loss: 0.2883 - val_accuracy: 0.9812 - val_loss: 0.2630\n",
            "Epoch 29/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9666 - loss: 0.2603 - val_accuracy: 0.9812 - val_loss: 0.2482\n",
            "Epoch 30/30\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9721 - loss: 0.2582 - val_accuracy: 0.9812 - val_loss: 0.2345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx8_ruEIHHB0",
        "outputId": "99211170-f964-4653-f6b8-629d13aebdba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9634 - loss: 0.2730  \n",
            "Test Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_transaction = np.array([[0.8, 0.9, 0.7, 0.6, 0.9]])\n",
        "prediction = model.predict(sample_transaction)\n",
        "\n",
        "print(\"Fraud Probability:\", prediction[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_hbCGopHLP5",
        "outputId": "e348250e-a47e-4ae4-e055-a6f9e1713ac4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Fraud Probability: 0.9949306\n"
          ]
        }
      ]
    }
  ]
}